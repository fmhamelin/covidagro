{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bienvenue For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Bienvenue"},{"location":"#bienvenue","text":"For full documentation visit mkdocs.org .","title":"Bienvenue"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"TD1/","text":"Introduction \u00e0 la mod\u00e9lisation en \u00e9pid\u00e9miologie : COVID19 - 1\u00e8re flamb\u00e9e - croissance exponentielle des d\u00e9c\u00e8s Fr\u00e9d\u00e9ric Hamelin, le 22 Mars 2021. Mod\u00e8le \u00e9pid\u00e9miologique Dans ce premier TD, nous allons mod\u00e9liser la croissance initiale de l'\u00e9pid\u00e9mie de COVID19 en France sur la base des donn\u00e9es de d\u00e9c\u00e8s uniquement. Les variables du mod\u00e8le sont : S(t) : le nombre de personnes sensibles au temps t , I(t) : le nombre de personnes infect\u00e9es et infectieuses, R(t) : le nombre de personnes r\u00e9tablies ou gu\u00e9ries, D(t) : le nombre de personnes d\u00e9c\u00e9d\u00e9es. La taille de la population est N=S+I+R . Les param\u00e8tres du mod\u00e8les sont \\beta : le taux de transmission de la maladie, \\gamma : le taux de gu\u00e9rison, \\alpha : le taux de mortalit\u00e9 due \u00e0 la maladie. Ce sont des \"taux\" par unit\u00e9 de temps. Le mod\u00e8le s'\u00e9crit : \\begin{eqnarray} \\frac{\\mathrm{d}S}{\\mathrm{d}t}&=&-\\beta \\frac{I}{N}S\\,,\\\\ \\frac{\\mathrm{d}I}{\\mathrm{d}t}&=&\\beta \\frac{I}{N}S - (\\alpha+\\gamma)I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,,\\\\ \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray} Comme nous nous int\u00e9ressons \u00e0 la phase initiale de l'\u00e9pid\u00e9mie, nous faisons l'hypoth\u00e8se que pour tout t dans cette phase initiale, I,R,D \\ll S , de sorte que S\\approx N (la taille de la population est approximativement constante durant cette p\u00e9riode). Le mod\u00e8le simplifi\u00e9 s'\u00e9crit : \\begin{eqnarray} \\frac{\\mathrm{d}I}{\\mathrm{d}t}&=&(\\beta - \\alpha-\\gamma)I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,,\\\\ \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray} Ainsi, I(t) = I(0)\\exp\\left(\\left(\\beta-\\alpha-\\gamma\\right)t\\right), et \\begin{eqnarray} D(t)&=&D(0)+\\int_0^t\\alpha I(\\tau) \\mathrm{d}\\tau\\,,\\\\ &=& D(0)+\\alpha\\int_0^t I(0)\\exp\\left(\\left(\\beta-\\alpha-\\gamma\\right)\\tau\\right) \\mathrm{d}\\tau\\,,\\\\ &=& D(0) + \\frac{\\alpha I(0)}{\\beta-\\alpha-\\gamma}\\left[\\exp\\left(\\left(\\beta-\\alpha-\\gamma\\right)t\\right)-1\\right]\\,. \\end{eqnarray} Soient r=\\beta-\\alpha-\\gamma\\,,\\quad\\mbox{et}\\quad q=\\alpha I(0)\\,. Le mod\u00e8le s'\u00e9crit enfin D(t)=D(0)+\\frac{q}{r}\\left(\\exp(rt)-1\\right)\\,. Selon le mod\u00e8le, le nombre de d\u00e9c\u00e8s cumul\u00e9s cro\u00eet de fa\u00e7on exponentielle en fonction du temps. Traitement des donn\u00e9es Commen\u00e7ons par nettoyer le plan de travail : rm(list=ls()) # Efface les variables cr\u00e9\u00e9es lors des ex\u00e9cutions pr\u00e9c\u00e9dentes graphics.off() # Ferme les fen\u00eatres ouvertes lors des ex\u00e9cutions pr\u00e9c\u00e9dentes Nous aurons besoin de la librairie readr : library(readr) # N\u00e9cessaire pour utiliser la fonction read_csv ci-dessous Importons les Donn\u00e9es relatives \u00e0 l\u2019\u00e9pid\u00e9mie de COVID-19 en France : vue d\u2019ensemble : data <- read_csv(url(\"https://www.data.gouv.fr/fr/datasets/r/d3a98a30-893f-47f7-96c5-2f4bcaaa0d71\")) Rempla\u00e7ons les donn\u00e9es manquantes par des z\u00e9ros pour faciliter le traitement des donn\u00e9es ensuite : data[is.na(data)]=0 Nous sommes int\u00e9ress\u00e9s par les d\u00e9c\u00e8s totaux (h\u00f4pital + EHPAD) : Dobs=data$total_deces_hopital+data$total_deces_ehpad # d\u00e9c\u00e8s cumul\u00e9s Affichons les d\u00e9c\u00e8s en fonction du temps : L=length(data$date) # longueur de la s\u00e9rie de donn\u00e9es Tobs=seq(0,L-1,by=1) # Vecteur temps plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de personnes d\u00e9c\u00e9d\u00e9es\",col=\"blue\") Restreignons la p\u00e9riode \u00e9tudi\u00e9e au mois de mars 2020 (1\u00e8re flamb\u00e9e) : Tmax=30 # Fin de la fen\u00eatre temporelle (le 31 mars 2020) w=seq(0,Tmax,by=1) # Fen\u00eatre temporelle consid\u00e9r\u00e9e Tobs=Tobs[w] # Troncation des donn\u00e9es Dobs=Dobs[w] Affichons les d\u00e9c\u00e8s cumul\u00e9s sur cette p\u00e9riode : La croissance est-elle exponentielle ? Si oui, le logarithme du nombre de d\u00e9c\u00e8s devrait cro\u00eetre de fa\u00e7on lin\u00e9aire en fonction du temps : plot(Tobs,log(Dobs),xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Log(Nombre de d\u00e9c\u00e8s cumul\u00e9s)\",col=\"blue\") reg=lm(log(Dobs)~Tobs) # R\u00e9gression lin\u00e9aire intercept=reg$coefficients[[1]] slope=reg$coefficients[[2]] abline(reg) Nous voyons que la croissance du logarithme est relativement lin\u00e9aire sur la p\u00e9riode consid\u00e9r\u00e9e. L'hypoth\u00e8se d'une croissance exponentielle du nombre de d\u00e9c\u00e8s cumul\u00e9s para\u00eet raisonnable sur la p\u00e9riode consid\u00e9r\u00e9e (mars 2020). Ajustement du mod\u00e8le aux donn\u00e9es Au 2 mars ( t=0 ), le nombre de d\u00e9c\u00e8s cumul\u00e9s est D(0)=3 : D0=Dobs[1] # Donn\u00e9e initiale Comme D(0) est petit par rapport au nombre de d\u00e9c\u00e8s cumul\u00e9s (ce nombre d\u00e9passe 3000 \u00e0 la fin du mois de mars), on peut consid\u00e9rer la relation suivante en premi\u00e8re et grossi\u00e8re approximation : D(t)=D(0)+\\frac{q}{r}\\left(\\exp(rt)-1\\right))\\approx \\frac{q}{r}\\exp(rt)\\,. Cela donne \\log(D(t))\\approx\\log\\left(\\frac{q}{r}\\right)+rt\\,, ce qui permet d'obtenir des estimations initiales des valeurs des param\u00e8tres r et q d'apr\u00e8s la r\u00e9gression lin\u00e9aire r\u00e9alis\u00e9e pr\u00e9c\u00e9demment : #estimations grossi\u00e8res initiales r=slope # r = beta - alpha - gamma q=r*exp(intercept) # q = alpha*I_0 Calculons la courbe issue du mod\u00e8le pour ces valeurs de param\u00e8tres : Tmodel=Tobs # on calcule la solution du mod\u00e8le pour les dates d'observation Dmodel=D0 + (q/r)*(exp(r*Tmodel)-1) Comparons le mod\u00e8le aux donn\u00e9es : plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de d\u00e9c\u00e8s cumul\u00e9s\",col=\"blue\") lines(Tmodel,Dmodel,col=\"red\") L'ajustement pourrait \u00eatre meilleur. Appelons \\theta=\\{r,q\\} le vecteur des param\u00e8tres \u00e0 optimiser : theta=c(r,q) # Vecteur des param\u00e8tres \u00e0 optimiser M\u00e9thode des moindres carr\u00e9s Recherchons les valeurs des param\u00e8tres r et q qui minimisent la somme des carr\u00e9s des \u00e9carts entre mod\u00e8le et donn\u00e9es (SCE) : \\mbox{SCE} = \\sum_{t=0}^T \\left(D_{\\small\\mbox{model}}(t)-D_{\\small\\mbox{data}}(t)\\right)^2\\,. Cr\u00e9ons une fonction qui prend en entr\u00e9e les param\u00e8tres \u00e0 optimiser et renvoie en sortie la quantit\u00e9 \u00e0 minimiser (SCE) : SCE_Covid=function(theta){ r=theta[1] q=theta[2] Dmodel = D0 + (q/r)*(exp(r*Tmodel)-1) ecarts = Dobs - Dmodel SCE = sum(ecarts^2) return(SCE) } Cherchons les valeurs des param\u00e8tres qui minimisent SCE : opt=optim(theta,SCE_Covid) # La fonction optim minimise par d\u00e9faut r=opt$par[1] q=opt$par[2] Affichons la solution optimale au sens des moindres carr\u00e9s : plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de d\u00e9c\u00e8s cumul\u00e9s\",col=\"blue\") lines(Tmodel,Dmodel,col=\"red\") L'ajustement est meilleur que celui obtenu en premi\u00e8re et grossi\u00e8re approximation. Affichons les valeurs des param\u00e8tres obtenues : print(r) print(q) On trouve r \\approx 0.17 et q \\approx 4.11 . M\u00e9thode du maximum de vraisemblance Une m\u00e9thode alternative consiste \u00e0 maximiser la probabilit\u00e9 des observations sachant les param\u00e8tres. C'est ce qu'on appelle la vraisemblance ( likelihood en anglais). Nous faisons l'hypoth\u00e8se que le nombre de d\u00e9c\u00e8s cumul\u00e9s observ\u00e9 au jour t est tir\u00e9 dans une loi de Poisson de moyenne D(t) tel que donn\u00e9 par le mod\u00e8le : D_{\\small\\mbox{data}}(t)\\sim \\mbox{Poisson}\\left(D_{\\small\\mbox{model}}(t)\\right) En admettant que les observations sont ind\u00e9pendantes conditionnellement au mod\u00e8le, la vraisemblance s'\u00e9crit : \\mbox{Like}(\\theta)=\\prod_{t=0}^{T} \\mbox{Prob}(\\mbox{observer }D_{\\small\\mbox{data}}(t)|D_{\\small\\mbox{model}}(t))\\,. Rechercher les valeurs de \\theta qui maximisent la vraisemblance est \u00e9quivalent \u00e0 rechercher les valeurs de \\theta qui maximisent la log-vraisemblance, qui transforme le produit en somme : \\mbox{logLike}(\\theta)=\\log(\\mbox{Like}(\\theta))=\\sum_{t=0}^T \\log\\left (\\mbox{Prob}(\\mbox{observer }D_{\\small\\mbox{data}}(t)|D_{\\small\\mbox{model}}(t))\\right )\\,. Cr\u00e9ons une fonction qui prend en entr\u00e9e les param\u00e8tres \u00e0 optimiser et renvoie en sortie la quantit\u00e9 \u00e0 minimiser (-logLike) : LL_Covid=function(theta){ #Log-likelihood r=theta[1] q=theta[2] Dmodel = D0 + (q/r)*(exp(r*Tmodel)-1) probas = dpois(Dobs,Dmodel) LL=sum(log(probas)) return(-LL) #on renvoie l'oppos\u00e9 pour minimiser } Cherchons les valeurs des param\u00e8tres qui maximisent logLike : opt=optim(theta,LL_Covid) r=opt$par[1] q=opt$par[2] Affichons la solution optimale au sens du maximum de vraisemblance : plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de d\u00e9c\u00e8s cumul\u00e9s\",col=\"blue\") lines(Tmodel,Dmodel,col=\"red\") L'ajustement est comparable \u00e0 celui obtenu via les moindres carr\u00e9s. Affichons les valeurs des param\u00e8tres obtenues : print(r) print(q) On trouve r \\approx 0.19 et q \\approx 2.47 , ce qui diff\u00e8re un peu des valeurs obtenues via les moindres carr\u00e9s. Interpr\u00e9tation des r\u00e9sultats L'ajustement du mod\u00e8le aux donn\u00e9es a permis de confirmer le caract\u00e8re exponentiel de la dynamique \u00e9pid\u00e9mique durant la premi\u00e8re flamb\u00e9e, telle que mesur\u00e9e par les d\u00e9c\u00e8s cumul\u00e9s en mars 2020, d'estimer les param\u00e8tres r=\\beta-\\alpha-\\gamma et q=\\alpha I(0) . En admettant que le taux de mortalit\u00e9 due \u00e0 la maladie (\\alpha) est tr\u00e8s petit devant le taux de gu\u00e9rison (\\gamma) , nous avons l'approximation r\\approx \\beta - \\gamma . Cela permet d'estimer la reproductivit\u00e9 du virus ( \\mathcal{R}_0 ), d\u00e9finie comme le nombre d'infections secondaires g\u00e9n\u00e9r\u00e9es par un individu infect\u00e9 dans une population initialement na\u00efve : \\mathcal{R}_0 = \\frac{\\beta}{\\alpha+\\gamma}\\approx \\frac{\\beta}{\\gamma} \\approx 1 + \\frac{r}{\\gamma}\\,. Admettons que le temps de gu\u00e9rison est de 10 jours en moyenne, soit \\gamma=0.1 par jour. On obtient : \\mathcal{R}_0\\approx 2.74 via la m\u00e9thode des moindres carr\u00e9s, \\mathcal{R}_0\\approx 2.98 via la m\u00e9thode du maximum de vraisemblance. Ces estimations sont coh\u00e9rentes avec celles obtenues par diff\u00e9rentes \u00e9tudes (ex. Roques et al 2020 ). Le taux de l\u00e9talit\u00e9 du virus (la probabilit\u00e9 moyenne de mourir lorsqu'on est infect\u00e9) est p=\\frac{\\alpha}{\\alpha+\\gamma}\\,. Supposons p=0.8\\% ( Roques et al 2020 ), ce qui donne \\alpha=p\\gamma/(1-p)\\approx p\\gamma = .0008 . Nous obtenons I(0)=q/\\alpha\\approx 5145 via les moindres carr\u00e9s, I(0)=q/\\alpha\\approx 3092 via le maximum de vraisemblance. Le mod\u00e8le permet d'estimer un ordre de grandeur du nombre total de personnes infect\u00e9es et infectieuses au 3 mars, alors que le nombre total de cas confirm\u00e9s \u00e0 cette date s'\u00e9levait \u00e0 191 d'apr\u00e8s les Donn\u00e9es relatives \u00e0 l\u2019\u00e9pid\u00e9mie de COVID-19 en France : vue d\u2019ensemble . D'apr\u00e8s le mod\u00e8le, on aurait approximativement 4000/200=20 personnes infect\u00e9es pour 1 cas confirm\u00e9 au 2 mars 2020.","title":"TD1"},{"location":"TD1/#introduction-a-la-modelisation-en-epidemiologie-covid19-1ere-flambee-croissance-exponentielle-des-deces","text":"Fr\u00e9d\u00e9ric Hamelin, le 22 Mars 2021.","title":"Introduction \u00e0 la mod\u00e9lisation en \u00e9pid\u00e9miologie : COVID19 - 1\u00e8re flamb\u00e9e - croissance exponentielle des d\u00e9c\u00e8s"},{"location":"TD1/#modele-epidemiologique","text":"Dans ce premier TD, nous allons mod\u00e9liser la croissance initiale de l'\u00e9pid\u00e9mie de COVID19 en France sur la base des donn\u00e9es de d\u00e9c\u00e8s uniquement. Les variables du mod\u00e8le sont : S(t) : le nombre de personnes sensibles au temps t , I(t) : le nombre de personnes infect\u00e9es et infectieuses, R(t) : le nombre de personnes r\u00e9tablies ou gu\u00e9ries, D(t) : le nombre de personnes d\u00e9c\u00e9d\u00e9es. La taille de la population est N=S+I+R . Les param\u00e8tres du mod\u00e8les sont \\beta : le taux de transmission de la maladie, \\gamma : le taux de gu\u00e9rison, \\alpha : le taux de mortalit\u00e9 due \u00e0 la maladie. Ce sont des \"taux\" par unit\u00e9 de temps. Le mod\u00e8le s'\u00e9crit : \\begin{eqnarray} \\frac{\\mathrm{d}S}{\\mathrm{d}t}&=&-\\beta \\frac{I}{N}S\\,,\\\\ \\frac{\\mathrm{d}I}{\\mathrm{d}t}&=&\\beta \\frac{I}{N}S - (\\alpha+\\gamma)I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,,\\\\ \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray} Comme nous nous int\u00e9ressons \u00e0 la phase initiale de l'\u00e9pid\u00e9mie, nous faisons l'hypoth\u00e8se que pour tout t dans cette phase initiale, I,R,D \\ll S , de sorte que S\\approx N (la taille de la population est approximativement constante durant cette p\u00e9riode). Le mod\u00e8le simplifi\u00e9 s'\u00e9crit : \\begin{eqnarray} \\frac{\\mathrm{d}I}{\\mathrm{d}t}&=&(\\beta - \\alpha-\\gamma)I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,,\\\\ \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray} Ainsi, I(t) = I(0)\\exp\\left(\\left(\\beta-\\alpha-\\gamma\\right)t\\right), et \\begin{eqnarray} D(t)&=&D(0)+\\int_0^t\\alpha I(\\tau) \\mathrm{d}\\tau\\,,\\\\ &=& D(0)+\\alpha\\int_0^t I(0)\\exp\\left(\\left(\\beta-\\alpha-\\gamma\\right)\\tau\\right) \\mathrm{d}\\tau\\,,\\\\ &=& D(0) + \\frac{\\alpha I(0)}{\\beta-\\alpha-\\gamma}\\left[\\exp\\left(\\left(\\beta-\\alpha-\\gamma\\right)t\\right)-1\\right]\\,. \\end{eqnarray} Soient r=\\beta-\\alpha-\\gamma\\,,\\quad\\mbox{et}\\quad q=\\alpha I(0)\\,. Le mod\u00e8le s'\u00e9crit enfin D(t)=D(0)+\\frac{q}{r}\\left(\\exp(rt)-1\\right)\\,. Selon le mod\u00e8le, le nombre de d\u00e9c\u00e8s cumul\u00e9s cro\u00eet de fa\u00e7on exponentielle en fonction du temps.","title":"Mod\u00e8le \u00e9pid\u00e9miologique"},{"location":"TD1/#traitement-des-donnees","text":"Commen\u00e7ons par nettoyer le plan de travail : rm(list=ls()) # Efface les variables cr\u00e9\u00e9es lors des ex\u00e9cutions pr\u00e9c\u00e9dentes graphics.off() # Ferme les fen\u00eatres ouvertes lors des ex\u00e9cutions pr\u00e9c\u00e9dentes Nous aurons besoin de la librairie readr : library(readr) # N\u00e9cessaire pour utiliser la fonction read_csv ci-dessous Importons les Donn\u00e9es relatives \u00e0 l\u2019\u00e9pid\u00e9mie de COVID-19 en France : vue d\u2019ensemble : data <- read_csv(url(\"https://www.data.gouv.fr/fr/datasets/r/d3a98a30-893f-47f7-96c5-2f4bcaaa0d71\")) Rempla\u00e7ons les donn\u00e9es manquantes par des z\u00e9ros pour faciliter le traitement des donn\u00e9es ensuite : data[is.na(data)]=0 Nous sommes int\u00e9ress\u00e9s par les d\u00e9c\u00e8s totaux (h\u00f4pital + EHPAD) : Dobs=data$total_deces_hopital+data$total_deces_ehpad # d\u00e9c\u00e8s cumul\u00e9s Affichons les d\u00e9c\u00e8s en fonction du temps : L=length(data$date) # longueur de la s\u00e9rie de donn\u00e9es Tobs=seq(0,L-1,by=1) # Vecteur temps plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de personnes d\u00e9c\u00e9d\u00e9es\",col=\"blue\") Restreignons la p\u00e9riode \u00e9tudi\u00e9e au mois de mars 2020 (1\u00e8re flamb\u00e9e) : Tmax=30 # Fin de la fen\u00eatre temporelle (le 31 mars 2020) w=seq(0,Tmax,by=1) # Fen\u00eatre temporelle consid\u00e9r\u00e9e Tobs=Tobs[w] # Troncation des donn\u00e9es Dobs=Dobs[w] Affichons les d\u00e9c\u00e8s cumul\u00e9s sur cette p\u00e9riode : La croissance est-elle exponentielle ? Si oui, le logarithme du nombre de d\u00e9c\u00e8s devrait cro\u00eetre de fa\u00e7on lin\u00e9aire en fonction du temps : plot(Tobs,log(Dobs),xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Log(Nombre de d\u00e9c\u00e8s cumul\u00e9s)\",col=\"blue\") reg=lm(log(Dobs)~Tobs) # R\u00e9gression lin\u00e9aire intercept=reg$coefficients[[1]] slope=reg$coefficients[[2]] abline(reg) Nous voyons que la croissance du logarithme est relativement lin\u00e9aire sur la p\u00e9riode consid\u00e9r\u00e9e. L'hypoth\u00e8se d'une croissance exponentielle du nombre de d\u00e9c\u00e8s cumul\u00e9s para\u00eet raisonnable sur la p\u00e9riode consid\u00e9r\u00e9e (mars 2020).","title":"Traitement des donn\u00e9es"},{"location":"TD1/#ajustement-du-modele-aux-donnees","text":"Au 2 mars ( t=0 ), le nombre de d\u00e9c\u00e8s cumul\u00e9s est D(0)=3 : D0=Dobs[1] # Donn\u00e9e initiale Comme D(0) est petit par rapport au nombre de d\u00e9c\u00e8s cumul\u00e9s (ce nombre d\u00e9passe 3000 \u00e0 la fin du mois de mars), on peut consid\u00e9rer la relation suivante en premi\u00e8re et grossi\u00e8re approximation : D(t)=D(0)+\\frac{q}{r}\\left(\\exp(rt)-1\\right))\\approx \\frac{q}{r}\\exp(rt)\\,. Cela donne \\log(D(t))\\approx\\log\\left(\\frac{q}{r}\\right)+rt\\,, ce qui permet d'obtenir des estimations initiales des valeurs des param\u00e8tres r et q d'apr\u00e8s la r\u00e9gression lin\u00e9aire r\u00e9alis\u00e9e pr\u00e9c\u00e9demment : #estimations grossi\u00e8res initiales r=slope # r = beta - alpha - gamma q=r*exp(intercept) # q = alpha*I_0 Calculons la courbe issue du mod\u00e8le pour ces valeurs de param\u00e8tres : Tmodel=Tobs # on calcule la solution du mod\u00e8le pour les dates d'observation Dmodel=D0 + (q/r)*(exp(r*Tmodel)-1) Comparons le mod\u00e8le aux donn\u00e9es : plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de d\u00e9c\u00e8s cumul\u00e9s\",col=\"blue\") lines(Tmodel,Dmodel,col=\"red\") L'ajustement pourrait \u00eatre meilleur. Appelons \\theta=\\{r,q\\} le vecteur des param\u00e8tres \u00e0 optimiser : theta=c(r,q) # Vecteur des param\u00e8tres \u00e0 optimiser","title":"Ajustement du mod\u00e8le aux donn\u00e9es"},{"location":"TD1/#methode-des-moindres-carres","text":"Recherchons les valeurs des param\u00e8tres r et q qui minimisent la somme des carr\u00e9s des \u00e9carts entre mod\u00e8le et donn\u00e9es (SCE) : \\mbox{SCE} = \\sum_{t=0}^T \\left(D_{\\small\\mbox{model}}(t)-D_{\\small\\mbox{data}}(t)\\right)^2\\,. Cr\u00e9ons une fonction qui prend en entr\u00e9e les param\u00e8tres \u00e0 optimiser et renvoie en sortie la quantit\u00e9 \u00e0 minimiser (SCE) : SCE_Covid=function(theta){ r=theta[1] q=theta[2] Dmodel = D0 + (q/r)*(exp(r*Tmodel)-1) ecarts = Dobs - Dmodel SCE = sum(ecarts^2) return(SCE) } Cherchons les valeurs des param\u00e8tres qui minimisent SCE : opt=optim(theta,SCE_Covid) # La fonction optim minimise par d\u00e9faut r=opt$par[1] q=opt$par[2] Affichons la solution optimale au sens des moindres carr\u00e9s : plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de d\u00e9c\u00e8s cumul\u00e9s\",col=\"blue\") lines(Tmodel,Dmodel,col=\"red\") L'ajustement est meilleur que celui obtenu en premi\u00e8re et grossi\u00e8re approximation. Affichons les valeurs des param\u00e8tres obtenues : print(r) print(q) On trouve r \\approx 0.17 et q \\approx 4.11 .","title":"M\u00e9thode des moindres carr\u00e9s"},{"location":"TD1/#methode-du-maximum-de-vraisemblance","text":"Une m\u00e9thode alternative consiste \u00e0 maximiser la probabilit\u00e9 des observations sachant les param\u00e8tres. C'est ce qu'on appelle la vraisemblance ( likelihood en anglais). Nous faisons l'hypoth\u00e8se que le nombre de d\u00e9c\u00e8s cumul\u00e9s observ\u00e9 au jour t est tir\u00e9 dans une loi de Poisson de moyenne D(t) tel que donn\u00e9 par le mod\u00e8le : D_{\\small\\mbox{data}}(t)\\sim \\mbox{Poisson}\\left(D_{\\small\\mbox{model}}(t)\\right) En admettant que les observations sont ind\u00e9pendantes conditionnellement au mod\u00e8le, la vraisemblance s'\u00e9crit : \\mbox{Like}(\\theta)=\\prod_{t=0}^{T} \\mbox{Prob}(\\mbox{observer }D_{\\small\\mbox{data}}(t)|D_{\\small\\mbox{model}}(t))\\,. Rechercher les valeurs de \\theta qui maximisent la vraisemblance est \u00e9quivalent \u00e0 rechercher les valeurs de \\theta qui maximisent la log-vraisemblance, qui transforme le produit en somme : \\mbox{logLike}(\\theta)=\\log(\\mbox{Like}(\\theta))=\\sum_{t=0}^T \\log\\left (\\mbox{Prob}(\\mbox{observer }D_{\\small\\mbox{data}}(t)|D_{\\small\\mbox{model}}(t))\\right )\\,. Cr\u00e9ons une fonction qui prend en entr\u00e9e les param\u00e8tres \u00e0 optimiser et renvoie en sortie la quantit\u00e9 \u00e0 minimiser (-logLike) : LL_Covid=function(theta){ #Log-likelihood r=theta[1] q=theta[2] Dmodel = D0 + (q/r)*(exp(r*Tmodel)-1) probas = dpois(Dobs,Dmodel) LL=sum(log(probas)) return(-LL) #on renvoie l'oppos\u00e9 pour minimiser } Cherchons les valeurs des param\u00e8tres qui maximisent logLike : opt=optim(theta,LL_Covid) r=opt$par[1] q=opt$par[2] Affichons la solution optimale au sens du maximum de vraisemblance : plot(Tobs,Dobs,xlab=\"Temps \u00e9coul\u00e9 depuis le 2 mars 2020 (en jours)\",ylab=\"Nombre de d\u00e9c\u00e8s cumul\u00e9s\",col=\"blue\") lines(Tmodel,Dmodel,col=\"red\") L'ajustement est comparable \u00e0 celui obtenu via les moindres carr\u00e9s. Affichons les valeurs des param\u00e8tres obtenues : print(r) print(q) On trouve r \\approx 0.19 et q \\approx 2.47 , ce qui diff\u00e8re un peu des valeurs obtenues via les moindres carr\u00e9s.","title":"M\u00e9thode du maximum de vraisemblance"},{"location":"TD1/#interpretation-des-resultats","text":"L'ajustement du mod\u00e8le aux donn\u00e9es a permis de confirmer le caract\u00e8re exponentiel de la dynamique \u00e9pid\u00e9mique durant la premi\u00e8re flamb\u00e9e, telle que mesur\u00e9e par les d\u00e9c\u00e8s cumul\u00e9s en mars 2020, d'estimer les param\u00e8tres r=\\beta-\\alpha-\\gamma et q=\\alpha I(0) . En admettant que le taux de mortalit\u00e9 due \u00e0 la maladie (\\alpha) est tr\u00e8s petit devant le taux de gu\u00e9rison (\\gamma) , nous avons l'approximation r\\approx \\beta - \\gamma . Cela permet d'estimer la reproductivit\u00e9 du virus ( \\mathcal{R}_0 ), d\u00e9finie comme le nombre d'infections secondaires g\u00e9n\u00e9r\u00e9es par un individu infect\u00e9 dans une population initialement na\u00efve : \\mathcal{R}_0 = \\frac{\\beta}{\\alpha+\\gamma}\\approx \\frac{\\beta}{\\gamma} \\approx 1 + \\frac{r}{\\gamma}\\,. Admettons que le temps de gu\u00e9rison est de 10 jours en moyenne, soit \\gamma=0.1 par jour. On obtient : \\mathcal{R}_0\\approx 2.74 via la m\u00e9thode des moindres carr\u00e9s, \\mathcal{R}_0\\approx 2.98 via la m\u00e9thode du maximum de vraisemblance. Ces estimations sont coh\u00e9rentes avec celles obtenues par diff\u00e9rentes \u00e9tudes (ex. Roques et al 2020 ). Le taux de l\u00e9talit\u00e9 du virus (la probabilit\u00e9 moyenne de mourir lorsqu'on est infect\u00e9) est p=\\frac{\\alpha}{\\alpha+\\gamma}\\,. Supposons p=0.8\\% ( Roques et al 2020 ), ce qui donne \\alpha=p\\gamma/(1-p)\\approx p\\gamma = .0008 . Nous obtenons I(0)=q/\\alpha\\approx 5145 via les moindres carr\u00e9s, I(0)=q/\\alpha\\approx 3092 via le maximum de vraisemblance. Le mod\u00e8le permet d'estimer un ordre de grandeur du nombre total de personnes infect\u00e9es et infectieuses au 3 mars, alors que le nombre total de cas confirm\u00e9s \u00e0 cette date s'\u00e9levait \u00e0 191 d'apr\u00e8s les Donn\u00e9es relatives \u00e0 l\u2019\u00e9pid\u00e9mie de COVID-19 en France : vue d\u2019ensemble . D'apr\u00e8s le mod\u00e8le, on aurait approximativement 4000/200=20 personnes infect\u00e9es pour 1 cas confirm\u00e9 au 2 mars 2020.","title":"Interpr\u00e9tation des r\u00e9sultats"},{"location":"TD2/","text":"Introduction \u00e0 la mod\u00e9lisation en \u00e9pid\u00e9miologie : COVID19 - 1\u00e8re flamb\u00e9e - estimation du taux de l\u00e9talit\u00e9 Marie Joigneau, Sabine Lobligeois, Louise Belamy, Maimouna Diarra (M1 Agro Rennes), le 14/03/2021. Edit\u00e9 par Fr\u00e9d\u00e9ric Hamelin, le 23/03/2021. Introduction On se base sur l\u2019\u00e9tude de l\u2019article suivant : Roques et al. (2020) Using Early Data to Estimate the Actual Infection Fatality Ratio from COVID-19 in France . Le but de notre \u00e9tude est de reproduire les r\u00e9sultats de l\u2019article avec les donn\u00e9es de morts actualis\u00e9es et publi\u00e9es par Sant\u00e9 Publique France . Mod\u00e8le \u00e9pid\u00e9miologique Dans ce TD, nous allons mod\u00e9liser la croissance initiale de l'\u00e9pid\u00e9mie de COVID19 en France sur la base des donn\u00e9es de tests dans un premier temps. Les donn\u00e9es concernant les d\u00e9c\u00e8s seront utilis\u00e9es dans un second temps pour estimer le taux de l\u00e9talit\u00e9 de la maladie au d\u00e9but de l'ann\u00e9e 2020 en France. Les variables du mod\u00e8le sont : S(t) : le nombre de personnes sensibles au temps t , I(t) : le nombre de personnes infect\u00e9es et infectieuses, R(t) : le nombre de personnes r\u00e9tablies ou gu\u00e9ries, D(t) : le nombre de personnes d\u00e9c\u00e9d\u00e9es. La taille de la population est N=S+I+R . Les param\u00e8tres du mod\u00e8les sont \\beta : le taux de transmission de la maladie, \\gamma : le taux de gu\u00e9rison, \\alpha : le taux de mortalit\u00e9 due \u00e0 la maladie. Ce sont des \"taux\" par unit\u00e9 de temps. Le mod\u00e8le s'\u00e9crit : \\begin{eqnarray} \\frac{\\mathrm{d}S}{\\mathrm{d}t}&=&-\\beta \\frac{I}{N}S\\,,\\\\ \\frac{\\mathrm{d}I}{\\mathrm{d}t}&=&\\beta \\frac{I}{N}S - (\\alpha+\\gamma)I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,,\\\\ \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray} Pour simplifier l'\u00e9tude, nous faisons l'hypoth\u00e8se que le taux de mortalit\u00e9 due \u00e0 la maladie est tr\u00e8s faible et n\u00e9gligeable d'un point de vue \u00e9pid\u00e9miologique devant le taux de gu\u00e9rison (\\alpha\\ll \\gamma) . Cela permet de d\u00e9composer le mod\u00e8le en deux parties, la premi\u00e8re \u00e9tant ind\u00e9pendante des d\u00e9c\u00e8s : \\begin{eqnarray} \\frac{\\mathrm{d}S}{\\mathrm{d}t}&=&-\\beta \\frac{I}{N}S\\,,\\\\ \\frac{\\mathrm{d}I}{\\mathrm{d}t}&\\approx&\\beta \\frac{I}{N}S -\\gamma I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,. \\end{eqnarray} Elle sera ajust\u00e9e aux donn\u00e9es de tests. La seconde partie du mod\u00e8le sera ajust\u00e9e aux donn\u00e9es de d\u00e9c\u00e8s : \\begin{eqnarray} \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray} Traitement des donn\u00e9es Commen\u00e7ons par nettoyer l'environnement de travail : rm(list=ls()) # Efface les variables cr\u00e9\u00e9es lors des ex\u00e9cutions pr\u00e9c\u00e9dentes graphics.off() # Ferme les fen\u00eatres ouvertes lors des ex\u00e9cutions pr\u00e9c\u00e9dentes On charge les librairies suivantes : library(deSolve) # pour r\u00e9soudre le syst\u00e8me d'\u00e9quations diff\u00e9rentielles (mod\u00e8le SIRD) library(R.matlab) # pour lire les fichiers de donn\u00e9es au format matlab library(downloader) # pour faciliter le t\u00e9l\u00e9chargement des donn\u00e9es library(zoo) # pour la moyenne mobile library(readr) # pour utiliser la fonction read_csv On t\u00e9l\u00e9charge l'archive contenant les donn\u00e9es utilis\u00e9es par Roques et al 2020 : download(\"https://www.mdpi.com/2079-7737/9/5/97/s1\", dest=\"suppMat.zip\", mode=\"wb\") On d\u00e9compresse l'archive : unzip(\"dataset.zip\", exdir = \"suppMat\") On r\u00e9cup\u00e8re les donn\u00e9es relatives aux tests (du 1er janvier au 17 mars) : dataT = readMat(\"./suppMat/data_smooth5.mat\") TP=as.integer(dataT$DATA[1,]) # nombre de tests positifs cumul\u00e9s TT=as.integer(dataT$DATA[2,]) # nombre total de tests cumul\u00e9s LT=length(TP) # Longueur de la s\u00e9rie temporelle On r\u00e9cup\u00e8re les donn\u00e9es relatives aux d\u00e9c\u00e8s (\u00e0 partir du 2 mars) : dataD <- read_csv(url(\"https://www.data.gouv.fr/fr/datasets/r/d3a98a30-893f-47f7-96c5-2f4bcaaa0d71\")) dataD[is.na(dataD)]=0 # on remplace les donn\u00e9es manquantes par des z\u00e9ros avant de sommer DC=dataD$total_deces_hopital+dataD$total_deces_ehpad # nombre de d\u00e9c\u00e8s cumul\u00e9s On cr\u00e9e un vecteur des d\u00e9c\u00e8s cumul\u00e9s du 1er janvier au 17 mars : # Les donn\u00e9es de d\u00e9c\u00e8s sont disponible \u00e0 partir du 2 mars n=31+29+1 # nombre de jours en janvier + f\u00e9vrier 2020 + 1 mars zeros=rep(0,n) # nombre de z\u00e9ros \u00e0 ajouter pour janvier/f\u00e9vrier m=17-1 # la fen\u00eatre de l'\u00e9tude s'arr\u00eate au 17 mars DC = c(zeros,DC[1:m]) # les d\u00e9c\u00e8s cumul\u00e9s du 1er janvier au 17 mars On cr\u00e9e un vecteur pour le taux de positivit\u00e9 cumul\u00e9 : PP=TP/TT # taux de positivit\u00e9 cumul\u00e9 On cr\u00e9e un vecteur temps : temps=seq.Date(from=as.Date(\"2020-01-01\"), to=as.Date(\"2020-03-17\"), by=\"days\") On affiche les tests cumul\u00e9s en fonction du temps : plot(temps,TT,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de tests\",col=\"black\") points(temps,TP,col=\"red\") legend(\"topleft\",c(\"Nombre de tests positifs\",\"Nombre de tests realises\"), fill=c(\"red\",\"black\")) title(\"Resultats cumules des tests realises de covid 19\") On affiche la proportion de tests positifs en fonction du temps : plot(temps,PP,xlab=\"Date (Annee 2020)\",ylab=\"Proportion de tests positifs\",col=\"purple\") title(\"Proportion de tests positifs en fonction du temps\") On affiche les d\u00e9c\u00e8s cumul\u00e9s en fonction du temps : plot(temps,DC,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de morts\",col=\"orange\") title(\"Morts cumules du covid 19\") On retrouve les donn\u00e9es non-cumul\u00e9es en utilisant la fonction diff : tt=diff(TT) # nombre quotidien de tests r\u00e9alis\u00e9s tp=diff(TP) # nombre quotidien de tests positifs dc=diff(DC) # nombre quotidien de d\u00e9c\u00e8s lt=length(tt) # longueur de la s\u00e9rie temporelle (l=L-1) On utilise donc un intervalle de temps qui commence le 2 janvier 2020 : temps2=seq.Date(from=as.Date(\"2020-01-02\"), to=as.Date(\"2020-03-17\"), by=\"days\") On affiche les tests quotidiens en fonction du temps : plot(temps2,tt,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de tests quotidiens\",col=\"black\") points(temps2,tp,col=\"red\") legend(\"topleft\",c(\"Nombre de tests positifs\",\"Nombre de tests realises\"), fill=c(\"red\",'black')) title(\"Resultats des tests quotidiens realises de covid 19\") On affiche le taux de positivit\u00e9 quotidien : pp=tp/tt # Proportion quotidienne de tests positifs plot(temps2,pp,xlab=\"Date (Annee 2020)\",ylab=\"Proportion de tests quotidiens positifs\",col=\"purple\") title(\"Proportion de tests positifs en fonction du temps\") On affiche les d\u00e9c\u00e8s quotidiens en fonction du temps : plot(temps2,dc,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de morts\",col=\"orange\") title(\"Morts quotidiens du covid 19\") Ajustement du mod\u00e8le aux donn\u00e9es Les param\u00e8tres du mod\u00e8le sont : N=67e6; # Taille totale de la pop fran\u00e7aise gamma=1/10; # \"taux\" de guerison par jour (1/gamma est la periode infectieuse) R_0=3; # Reproductivite de la maladie beta=gamma*R_0; # R0=beta/alpha (estimation initiale \u00e0 optimiser) sigma=0.7;# Sensibilite des tests PCR kappa=5e-3# Probabilit\u00e9 relative pour les sensibles de se faire tester comparativement aux infect\u00e9s (estimation initiale \u00e0 optimiser) Les conditions initiales du mod\u00e8le sont : I0=1; # On part d'un individu infect\u00e9. Ceci est fix\u00e9 pour la premiere flamb\u00e9e. R0=0; # On suppose que personne n'est immunis\u00e9 dans la population initialement. S0=N-I0-R0; # Nombre initial de sensibles (tout le monde sauf le premier infect\u00e9) X0=c(S0,I0); # Vecteur d'etat Cr\u00e9ons une fonction qui permet de simuler le mod\u00e8le SIR : SIR = function(t, X, P){ beta=P[1] # beta est le premier et unique \u00e9l\u00e9ment du vecteur des param\u00e8tres P # gamma est un param\u00e8tre dont la valeur est fix\u00e9e de fa\u00e7on globale S=X[1] # S est le premier \u00e9l\u00e9ment du vecteur d'\u00e9tat X I=X[2] # I est le second \u00e9l\u00e9ment du vecteur d'\u00e9tat X y=beta*S*I/N # y est le nombre de nouvelles infections par unit\u00e9 de temps dS = -y # dS/dt : variation du nombre d'individus sains dI = +y - gamma*I # dI/dt : variation du nombre d'individus infect\u00e9s dX=c(dS,dI) return(list(dX)) # la liste dX contient dS et dI les deriv\u00e9es de S et I } Cr\u00e9ons une fonction qui permet de calculer la vraisemblance associ\u00e9e \u00e0 un vecteur de param\u00e8tres \u00e0 optimiser \\theta = \\{ \\beta, \\kappa \\} . logLike = function(theta){ # theta est le vecteur des param\u00e8tres beta=theta[1] # beta est le premier \u00e9l\u00e9ment du vecteur theta kappa=theta[2] # kappa est le second \u00e9l\u00e9ment du vecteur theta X=ode(X0,t,SIR,beta) # la fonction ode renvoie les solutions du modele SIR avec beta pour param\u00e8tre # X0 est le vecteur des conditions initiales # t est le vecteur des dates d'observations # La fonction ode renvoie un matrice X de la forme : # 1\u00e8re colonne : t, 2\u00e8me colonne : S(t), 3\u00e8me colonne : I(t) # Proportion th\u00e9orique de tests quotidiens positifs (information issue du modele) p=sigma*X[,3]/(X[,3]+kappa*X[,2]) # On met des zeros avant t0 (en pratique 1e-12 pour eviter log(0) plus bas) p=c(rep(1e-12,t0-1),p) # Probabilite d observer \"tp\" positifs sachant le nombre de tests \"tt\" # et \"p(t)\" telle que donn\u00e9e par le mod\u00e8le (loi binomiale de parametre \"pt\") L=dbinom(tp, tt, p, log=TRUE) # Vecteur des vraisemblances (likelihood) #Log = TRUE car on travaille sur la log-vraisemblance LL=sum(L) # Le log transforme le produit des probabilit\u00e9s en somme return(LL) # renvoie la Log-vraisemblance associ\u00e9e au jeu de param\u00e8tres theta } En plus des param\u00e8tres \\beta et \\kappa , nous souhaitons estimer la date initiale de l'\u00e9pid\u00e9mie, t_0 , telle que I(t_0)=I_0=1 . Comme t_0 est un entier, nous le traitons s\u00e9par\u00e9ment via une boucle d'optimisation qui parcours tous les t_0 possibles du 2 janvier au 1er f\u00e9vrier. V=-1e6 # Valeur initiale de la vraisemblance (\u00e0 maximiser) for (t0 in 1:31){ # Boucle d'optimisation sur les t0 t=t0:lt # Vecteur temps : dates sur lesquelles on simule le mod\u00e8le theta0=c(beta,kappa) # Vecteur des parametres a estimer (estimations initiales) opt=optim(theta0,logLike,control=list(fnscale=-1)); # Part d'un point de depart theta0 et suit la plus forte pente (le gradient de la log-vraisemblance en fonction de theta) jusqu'\u00e0 maximiser la log-vraisemblance (localement) # Selon le point theta0 de d\u00e9part que l'on donne le maximum local renvoy\u00e9 peut varier if (opt$value>V){ #Si le t0 consid\u00e9r\u00e9 augmente la vraisemblance, V=opt$value #on sauvegarde la vraisemblance ainsi que t0, beta et gamma. t0opt=t0 beta=opt$par[1] kappa=opt$par[2] } } On affiche les param\u00e8tres optimaux obtenus : print(t0opt) print(kappa) print(beta) On trouve t_0 = 22 jours (soit le 23 janvier), \\kappa \\approx .0004 , \\beta \\approx 0.3 , ce qui permet d'estimer la reproductivit\u00e9 du virus ( \\mathcal{R}_0 ), d\u00e9finie comme le nombre d'infections secondaires g\u00e9n\u00e9r\u00e9es par un individu infect\u00e9 dans une population initialement na\u00efve : \\mathcal{R}_0 = \\frac{\\beta}{\\alpha+\\gamma}\\approx \\frac{\\beta}{\\gamma} \\approx 3\\,, \u200b puisque \\gamma=0.1 par jour. Ces estimations sont coh\u00e9rentes avec celles obtenues par Roques et al 2020 . t=t0opt:lt # nouveau vecteur temps X=ode(X0,t,SIR,beta) # simulation du mod\u00e8le SIR La proportion th\u00e9orique de tests quotidiens positifs est : p=sigma*X[,3]/(X[,3]+kappa*X[,2]) # p(t) = sigma I(t)/(I(t) + kappa S(t)) Les tests positifs cumul\u00e9s observ\u00e9s sont : Sigma1=cumsum(tp[t]) # on reprend les notations de l'article Roques et al (2020) Tests positifs cumul\u00e9s th\u00e9oriques sont : Sigma2=cumsum(tt[t]*p) # on reprend les notations de l'article Roques et al (2020) On d\u00e9finit la premi\u00e8re flamb\u00e9e entre le 22 janvier et le 17 mars 2020 : temps3=seq.Date(from=as.Date(\"2020-01-23\"), to=as.Date(\"2020-03-17\"), by=\"days\") On affiche le nombre de tests positifs cumul\u00e9s en fonction du temps : plot(temps3,Sigma1,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de tests positifs cumules\",col=\"black\") lines(temps3,Sigma2, col='red') legend(\"topleft\",c(\"D'apres les donnees\",\"D'apres le modele\"),fill=c('black','red')) title(\"Comparaison des tests positifs cumules des donnees et du modele\") On retrouve le graphe de l\u2019article Roques et al 2020 (Fig. 1) donc l\u2019article est bien reproductible. On affiche le nombre de cas infectieux I(t) et infect\u00e9s (N-S(t)) en fonction du temps : plot(temps3,N-X[,2],col=\"red\",type=\"l\",xlab=\"Date (Annee 2020)\",ylab=\"Nombre de personnes\") lines(temps3,X[,3],col=\"purple\") lines(temps3,Sigma2) points(temps3,Sigma1) legend(\"topleft\",c(\"Nombre de personnes infectees\",\"Nombre de personnes infectieuses\",\"Nombre de personnes testees positives d'apres les donnees (points)\",\"d'apres le modele (courbe)\"),fill=c('red','purple','black','black'),cex=0.8) title(\"Evolution de la pandemie en France lors de la premiere flambee\") On retrouve approximativement la Figure 2 de l\u2019article Roques et al 2020 . On affiche le taux de positivit\u00e9 quotidien : plot(temps3,pp[t],xlab=\"Date (Annee 2020)\",ylab=\"Proportion de tests quotidiens positifs\") lines(temps3,p) legend(\"topleft\",c(\"D'apres les donnees (points)\",\"D'apres le modele (courbe)\")) title(\"Evolution de la proportion de tests positifs dans le temps\") Estimation du taux de l\u00e9talit\u00e9 Le taux de l\u00e9talit\u00e9 moyen (IFR pour infection fatality ratio ) est la proportion de morts parmi les personnes infect\u00e9es ou la probabilit\u00e9 de mourir des suites de l'infection : \\mbox{IFR}(t)=\\frac{\\alpha(t)}{\\alpha(t)+\\gamma}\\,. Nous ne supposons pas qu'il est constant au cours de l'\u00e9pid\u00e9mie. On estime \\alpha(t) (le taux de mortalit\u00e9 due \u00e0 la maladie) via la relation suivante : \\alpha(t)=\\frac{1}{I(t)}\\frac{\\mathrm{d} D(t)}{\\mathrm{d} t}\\,, o\u00f9 \\mathrm{d}D(t)/\\mathrm{d}t est le nombre de d\u00e9c\u00e8s quotidien. dc=dc[-(1:(t0opt-1))] # toncation des donn\u00e9es de d\u00e9c\u00e8s \u00e0 partir de t0 alpha=dc/X[,3] # estimation de alpha(t) = [dD(t)/dt]/I(t) IFR=alpha/(gamma+alpha) # taux de l\u00e9talit\u00e9 (infection fatality ratio) On affiche le taux de l\u00e9talit\u00e9 (IFR) brut : plot(temps3, IFR, type =\"l\", xlab=\"Date (Annee 2020)\", ylab=\"IFR\") On r\u00e9alise une moyenne de l\u2019IFR sur les valeurs non nulles : w=which(IFR!=0) print(mean(IFR[w])) On obtient un IFR de 0.67%. Cette valeur est comparable \u00e0 celles estim\u00e9es par Roques et al 2020 . On lisse la sortie en faisant une moyenne mobile sur 5 jours : IFRlisse <- rollmean(IFR, k=5) plot(t[1:length(IFRlisse)], IFRlisse, type =\"l\", xlab=\"Nombre de jours (du 1er janvier 2020 au 12 mars 2020)\", ylab=\"IFR\",ylim=c(0,0.01)) points(t, IFR) title(\"Evolution de l'IFR (ratio de letalite) lors de la premiere flambee\") Nous obtenons des valeurs d\u2019IFR du m\u00eame ordre de grandeur (0.8%) et de tendance comparable \u00e0 l'article de Roques et al 2020 .","title":"TD2"},{"location":"TD2/#introduction-a-la-modelisation-en-epidemiologie-covid19-1ere-flambee-estimation-du-taux-de-letalite","text":"Marie Joigneau, Sabine Lobligeois, Louise Belamy, Maimouna Diarra (M1 Agro Rennes), le 14/03/2021. Edit\u00e9 par Fr\u00e9d\u00e9ric Hamelin, le 23/03/2021.","title":"Introduction \u00e0 la mod\u00e9lisation en \u00e9pid\u00e9miologie : COVID19 - 1\u00e8re flamb\u00e9e - estimation du taux de l\u00e9talit\u00e9"},{"location":"TD2/#introduction","text":"On se base sur l\u2019\u00e9tude de l\u2019article suivant : Roques et al. (2020) Using Early Data to Estimate the Actual Infection Fatality Ratio from COVID-19 in France . Le but de notre \u00e9tude est de reproduire les r\u00e9sultats de l\u2019article avec les donn\u00e9es de morts actualis\u00e9es et publi\u00e9es par Sant\u00e9 Publique France .","title":"Introduction"},{"location":"TD2/#modele-epidemiologique","text":"Dans ce TD, nous allons mod\u00e9liser la croissance initiale de l'\u00e9pid\u00e9mie de COVID19 en France sur la base des donn\u00e9es de tests dans un premier temps. Les donn\u00e9es concernant les d\u00e9c\u00e8s seront utilis\u00e9es dans un second temps pour estimer le taux de l\u00e9talit\u00e9 de la maladie au d\u00e9but de l'ann\u00e9e 2020 en France. Les variables du mod\u00e8le sont : S(t) : le nombre de personnes sensibles au temps t , I(t) : le nombre de personnes infect\u00e9es et infectieuses, R(t) : le nombre de personnes r\u00e9tablies ou gu\u00e9ries, D(t) : le nombre de personnes d\u00e9c\u00e9d\u00e9es. La taille de la population est N=S+I+R . Les param\u00e8tres du mod\u00e8les sont \\beta : le taux de transmission de la maladie, \\gamma : le taux de gu\u00e9rison, \\alpha : le taux de mortalit\u00e9 due \u00e0 la maladie. Ce sont des \"taux\" par unit\u00e9 de temps. Le mod\u00e8le s'\u00e9crit : \\begin{eqnarray} \\frac{\\mathrm{d}S}{\\mathrm{d}t}&=&-\\beta \\frac{I}{N}S\\,,\\\\ \\frac{\\mathrm{d}I}{\\mathrm{d}t}&=&\\beta \\frac{I}{N}S - (\\alpha+\\gamma)I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,,\\\\ \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray} Pour simplifier l'\u00e9tude, nous faisons l'hypoth\u00e8se que le taux de mortalit\u00e9 due \u00e0 la maladie est tr\u00e8s faible et n\u00e9gligeable d'un point de vue \u00e9pid\u00e9miologique devant le taux de gu\u00e9rison (\\alpha\\ll \\gamma) . Cela permet de d\u00e9composer le mod\u00e8le en deux parties, la premi\u00e8re \u00e9tant ind\u00e9pendante des d\u00e9c\u00e8s : \\begin{eqnarray} \\frac{\\mathrm{d}S}{\\mathrm{d}t}&=&-\\beta \\frac{I}{N}S\\,,\\\\ \\frac{\\mathrm{d}I}{\\mathrm{d}t}&\\approx&\\beta \\frac{I}{N}S -\\gamma I\\,,\\\\ \\frac{\\mathrm{d}R}{\\mathrm{d}t}&=&\\gamma I\\,. \\end{eqnarray} Elle sera ajust\u00e9e aux donn\u00e9es de tests. La seconde partie du mod\u00e8le sera ajust\u00e9e aux donn\u00e9es de d\u00e9c\u00e8s : \\begin{eqnarray} \\frac{\\mathrm{d}D}{\\mathrm{d}t}&=&\\alpha I\\,. \\end{eqnarray}","title":"Mod\u00e8le \u00e9pid\u00e9miologique"},{"location":"TD2/#traitement-des-donnees","text":"Commen\u00e7ons par nettoyer l'environnement de travail : rm(list=ls()) # Efface les variables cr\u00e9\u00e9es lors des ex\u00e9cutions pr\u00e9c\u00e9dentes graphics.off() # Ferme les fen\u00eatres ouvertes lors des ex\u00e9cutions pr\u00e9c\u00e9dentes On charge les librairies suivantes : library(deSolve) # pour r\u00e9soudre le syst\u00e8me d'\u00e9quations diff\u00e9rentielles (mod\u00e8le SIRD) library(R.matlab) # pour lire les fichiers de donn\u00e9es au format matlab library(downloader) # pour faciliter le t\u00e9l\u00e9chargement des donn\u00e9es library(zoo) # pour la moyenne mobile library(readr) # pour utiliser la fonction read_csv On t\u00e9l\u00e9charge l'archive contenant les donn\u00e9es utilis\u00e9es par Roques et al 2020 : download(\"https://www.mdpi.com/2079-7737/9/5/97/s1\", dest=\"suppMat.zip\", mode=\"wb\") On d\u00e9compresse l'archive : unzip(\"dataset.zip\", exdir = \"suppMat\") On r\u00e9cup\u00e8re les donn\u00e9es relatives aux tests (du 1er janvier au 17 mars) : dataT = readMat(\"./suppMat/data_smooth5.mat\") TP=as.integer(dataT$DATA[1,]) # nombre de tests positifs cumul\u00e9s TT=as.integer(dataT$DATA[2,]) # nombre total de tests cumul\u00e9s LT=length(TP) # Longueur de la s\u00e9rie temporelle On r\u00e9cup\u00e8re les donn\u00e9es relatives aux d\u00e9c\u00e8s (\u00e0 partir du 2 mars) : dataD <- read_csv(url(\"https://www.data.gouv.fr/fr/datasets/r/d3a98a30-893f-47f7-96c5-2f4bcaaa0d71\")) dataD[is.na(dataD)]=0 # on remplace les donn\u00e9es manquantes par des z\u00e9ros avant de sommer DC=dataD$total_deces_hopital+dataD$total_deces_ehpad # nombre de d\u00e9c\u00e8s cumul\u00e9s On cr\u00e9e un vecteur des d\u00e9c\u00e8s cumul\u00e9s du 1er janvier au 17 mars : # Les donn\u00e9es de d\u00e9c\u00e8s sont disponible \u00e0 partir du 2 mars n=31+29+1 # nombre de jours en janvier + f\u00e9vrier 2020 + 1 mars zeros=rep(0,n) # nombre de z\u00e9ros \u00e0 ajouter pour janvier/f\u00e9vrier m=17-1 # la fen\u00eatre de l'\u00e9tude s'arr\u00eate au 17 mars DC = c(zeros,DC[1:m]) # les d\u00e9c\u00e8s cumul\u00e9s du 1er janvier au 17 mars On cr\u00e9e un vecteur pour le taux de positivit\u00e9 cumul\u00e9 : PP=TP/TT # taux de positivit\u00e9 cumul\u00e9 On cr\u00e9e un vecteur temps : temps=seq.Date(from=as.Date(\"2020-01-01\"), to=as.Date(\"2020-03-17\"), by=\"days\") On affiche les tests cumul\u00e9s en fonction du temps : plot(temps,TT,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de tests\",col=\"black\") points(temps,TP,col=\"red\") legend(\"topleft\",c(\"Nombre de tests positifs\",\"Nombre de tests realises\"), fill=c(\"red\",\"black\")) title(\"Resultats cumules des tests realises de covid 19\") On affiche la proportion de tests positifs en fonction du temps : plot(temps,PP,xlab=\"Date (Annee 2020)\",ylab=\"Proportion de tests positifs\",col=\"purple\") title(\"Proportion de tests positifs en fonction du temps\") On affiche les d\u00e9c\u00e8s cumul\u00e9s en fonction du temps : plot(temps,DC,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de morts\",col=\"orange\") title(\"Morts cumules du covid 19\") On retrouve les donn\u00e9es non-cumul\u00e9es en utilisant la fonction diff : tt=diff(TT) # nombre quotidien de tests r\u00e9alis\u00e9s tp=diff(TP) # nombre quotidien de tests positifs dc=diff(DC) # nombre quotidien de d\u00e9c\u00e8s lt=length(tt) # longueur de la s\u00e9rie temporelle (l=L-1) On utilise donc un intervalle de temps qui commence le 2 janvier 2020 : temps2=seq.Date(from=as.Date(\"2020-01-02\"), to=as.Date(\"2020-03-17\"), by=\"days\") On affiche les tests quotidiens en fonction du temps : plot(temps2,tt,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de tests quotidiens\",col=\"black\") points(temps2,tp,col=\"red\") legend(\"topleft\",c(\"Nombre de tests positifs\",\"Nombre de tests realises\"), fill=c(\"red\",'black')) title(\"Resultats des tests quotidiens realises de covid 19\") On affiche le taux de positivit\u00e9 quotidien : pp=tp/tt # Proportion quotidienne de tests positifs plot(temps2,pp,xlab=\"Date (Annee 2020)\",ylab=\"Proportion de tests quotidiens positifs\",col=\"purple\") title(\"Proportion de tests positifs en fonction du temps\") On affiche les d\u00e9c\u00e8s quotidiens en fonction du temps : plot(temps2,dc,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de morts\",col=\"orange\") title(\"Morts quotidiens du covid 19\")","title":"Traitement des donn\u00e9es"},{"location":"TD2/#ajustement-du-modele-aux-donnees","text":"Les param\u00e8tres du mod\u00e8le sont : N=67e6; # Taille totale de la pop fran\u00e7aise gamma=1/10; # \"taux\" de guerison par jour (1/gamma est la periode infectieuse) R_0=3; # Reproductivite de la maladie beta=gamma*R_0; # R0=beta/alpha (estimation initiale \u00e0 optimiser) sigma=0.7;# Sensibilite des tests PCR kappa=5e-3# Probabilit\u00e9 relative pour les sensibles de se faire tester comparativement aux infect\u00e9s (estimation initiale \u00e0 optimiser) Les conditions initiales du mod\u00e8le sont : I0=1; # On part d'un individu infect\u00e9. Ceci est fix\u00e9 pour la premiere flamb\u00e9e. R0=0; # On suppose que personne n'est immunis\u00e9 dans la population initialement. S0=N-I0-R0; # Nombre initial de sensibles (tout le monde sauf le premier infect\u00e9) X0=c(S0,I0); # Vecteur d'etat Cr\u00e9ons une fonction qui permet de simuler le mod\u00e8le SIR : SIR = function(t, X, P){ beta=P[1] # beta est le premier et unique \u00e9l\u00e9ment du vecteur des param\u00e8tres P # gamma est un param\u00e8tre dont la valeur est fix\u00e9e de fa\u00e7on globale S=X[1] # S est le premier \u00e9l\u00e9ment du vecteur d'\u00e9tat X I=X[2] # I est le second \u00e9l\u00e9ment du vecteur d'\u00e9tat X y=beta*S*I/N # y est le nombre de nouvelles infections par unit\u00e9 de temps dS = -y # dS/dt : variation du nombre d'individus sains dI = +y - gamma*I # dI/dt : variation du nombre d'individus infect\u00e9s dX=c(dS,dI) return(list(dX)) # la liste dX contient dS et dI les deriv\u00e9es de S et I } Cr\u00e9ons une fonction qui permet de calculer la vraisemblance associ\u00e9e \u00e0 un vecteur de param\u00e8tres \u00e0 optimiser \\theta = \\{ \\beta, \\kappa \\} . logLike = function(theta){ # theta est le vecteur des param\u00e8tres beta=theta[1] # beta est le premier \u00e9l\u00e9ment du vecteur theta kappa=theta[2] # kappa est le second \u00e9l\u00e9ment du vecteur theta X=ode(X0,t,SIR,beta) # la fonction ode renvoie les solutions du modele SIR avec beta pour param\u00e8tre # X0 est le vecteur des conditions initiales # t est le vecteur des dates d'observations # La fonction ode renvoie un matrice X de la forme : # 1\u00e8re colonne : t, 2\u00e8me colonne : S(t), 3\u00e8me colonne : I(t) # Proportion th\u00e9orique de tests quotidiens positifs (information issue du modele) p=sigma*X[,3]/(X[,3]+kappa*X[,2]) # On met des zeros avant t0 (en pratique 1e-12 pour eviter log(0) plus bas) p=c(rep(1e-12,t0-1),p) # Probabilite d observer \"tp\" positifs sachant le nombre de tests \"tt\" # et \"p(t)\" telle que donn\u00e9e par le mod\u00e8le (loi binomiale de parametre \"pt\") L=dbinom(tp, tt, p, log=TRUE) # Vecteur des vraisemblances (likelihood) #Log = TRUE car on travaille sur la log-vraisemblance LL=sum(L) # Le log transforme le produit des probabilit\u00e9s en somme return(LL) # renvoie la Log-vraisemblance associ\u00e9e au jeu de param\u00e8tres theta } En plus des param\u00e8tres \\beta et \\kappa , nous souhaitons estimer la date initiale de l'\u00e9pid\u00e9mie, t_0 , telle que I(t_0)=I_0=1 . Comme t_0 est un entier, nous le traitons s\u00e9par\u00e9ment via une boucle d'optimisation qui parcours tous les t_0 possibles du 2 janvier au 1er f\u00e9vrier. V=-1e6 # Valeur initiale de la vraisemblance (\u00e0 maximiser) for (t0 in 1:31){ # Boucle d'optimisation sur les t0 t=t0:lt # Vecteur temps : dates sur lesquelles on simule le mod\u00e8le theta0=c(beta,kappa) # Vecteur des parametres a estimer (estimations initiales) opt=optim(theta0,logLike,control=list(fnscale=-1)); # Part d'un point de depart theta0 et suit la plus forte pente (le gradient de la log-vraisemblance en fonction de theta) jusqu'\u00e0 maximiser la log-vraisemblance (localement) # Selon le point theta0 de d\u00e9part que l'on donne le maximum local renvoy\u00e9 peut varier if (opt$value>V){ #Si le t0 consid\u00e9r\u00e9 augmente la vraisemblance, V=opt$value #on sauvegarde la vraisemblance ainsi que t0, beta et gamma. t0opt=t0 beta=opt$par[1] kappa=opt$par[2] } } On affiche les param\u00e8tres optimaux obtenus : print(t0opt) print(kappa) print(beta) On trouve t_0 = 22 jours (soit le 23 janvier), \\kappa \\approx .0004 , \\beta \\approx 0.3 , ce qui permet d'estimer la reproductivit\u00e9 du virus ( \\mathcal{R}_0 ), d\u00e9finie comme le nombre d'infections secondaires g\u00e9n\u00e9r\u00e9es par un individu infect\u00e9 dans une population initialement na\u00efve : \\mathcal{R}_0 = \\frac{\\beta}{\\alpha+\\gamma}\\approx \\frac{\\beta}{\\gamma} \\approx 3\\,, \u200b puisque \\gamma=0.1 par jour. Ces estimations sont coh\u00e9rentes avec celles obtenues par Roques et al 2020 . t=t0opt:lt # nouveau vecteur temps X=ode(X0,t,SIR,beta) # simulation du mod\u00e8le SIR La proportion th\u00e9orique de tests quotidiens positifs est : p=sigma*X[,3]/(X[,3]+kappa*X[,2]) # p(t) = sigma I(t)/(I(t) + kappa S(t)) Les tests positifs cumul\u00e9s observ\u00e9s sont : Sigma1=cumsum(tp[t]) # on reprend les notations de l'article Roques et al (2020) Tests positifs cumul\u00e9s th\u00e9oriques sont : Sigma2=cumsum(tt[t]*p) # on reprend les notations de l'article Roques et al (2020) On d\u00e9finit la premi\u00e8re flamb\u00e9e entre le 22 janvier et le 17 mars 2020 : temps3=seq.Date(from=as.Date(\"2020-01-23\"), to=as.Date(\"2020-03-17\"), by=\"days\") On affiche le nombre de tests positifs cumul\u00e9s en fonction du temps : plot(temps3,Sigma1,xlab=\"Date (Annee 2020)\",ylab=\"Nombre de tests positifs cumules\",col=\"black\") lines(temps3,Sigma2, col='red') legend(\"topleft\",c(\"D'apres les donnees\",\"D'apres le modele\"),fill=c('black','red')) title(\"Comparaison des tests positifs cumules des donnees et du modele\") On retrouve le graphe de l\u2019article Roques et al 2020 (Fig. 1) donc l\u2019article est bien reproductible. On affiche le nombre de cas infectieux I(t) et infect\u00e9s (N-S(t)) en fonction du temps : plot(temps3,N-X[,2],col=\"red\",type=\"l\",xlab=\"Date (Annee 2020)\",ylab=\"Nombre de personnes\") lines(temps3,X[,3],col=\"purple\") lines(temps3,Sigma2) points(temps3,Sigma1) legend(\"topleft\",c(\"Nombre de personnes infectees\",\"Nombre de personnes infectieuses\",\"Nombre de personnes testees positives d'apres les donnees (points)\",\"d'apres le modele (courbe)\"),fill=c('red','purple','black','black'),cex=0.8) title(\"Evolution de la pandemie en France lors de la premiere flambee\") On retrouve approximativement la Figure 2 de l\u2019article Roques et al 2020 . On affiche le taux de positivit\u00e9 quotidien : plot(temps3,pp[t],xlab=\"Date (Annee 2020)\",ylab=\"Proportion de tests quotidiens positifs\") lines(temps3,p) legend(\"topleft\",c(\"D'apres les donnees (points)\",\"D'apres le modele (courbe)\")) title(\"Evolution de la proportion de tests positifs dans le temps\")","title":"Ajustement du mod\u00e8le aux donn\u00e9es"},{"location":"TD2/#estimation-du-taux-de-letalite","text":"Le taux de l\u00e9talit\u00e9 moyen (IFR pour infection fatality ratio ) est la proportion de morts parmi les personnes infect\u00e9es ou la probabilit\u00e9 de mourir des suites de l'infection : \\mbox{IFR}(t)=\\frac{\\alpha(t)}{\\alpha(t)+\\gamma}\\,. Nous ne supposons pas qu'il est constant au cours de l'\u00e9pid\u00e9mie. On estime \\alpha(t) (le taux de mortalit\u00e9 due \u00e0 la maladie) via la relation suivante : \\alpha(t)=\\frac{1}{I(t)}\\frac{\\mathrm{d} D(t)}{\\mathrm{d} t}\\,, o\u00f9 \\mathrm{d}D(t)/\\mathrm{d}t est le nombre de d\u00e9c\u00e8s quotidien. dc=dc[-(1:(t0opt-1))] # toncation des donn\u00e9es de d\u00e9c\u00e8s \u00e0 partir de t0 alpha=dc/X[,3] # estimation de alpha(t) = [dD(t)/dt]/I(t) IFR=alpha/(gamma+alpha) # taux de l\u00e9talit\u00e9 (infection fatality ratio) On affiche le taux de l\u00e9talit\u00e9 (IFR) brut : plot(temps3, IFR, type =\"l\", xlab=\"Date (Annee 2020)\", ylab=\"IFR\") On r\u00e9alise une moyenne de l\u2019IFR sur les valeurs non nulles : w=which(IFR!=0) print(mean(IFR[w])) On obtient un IFR de 0.67%. Cette valeur est comparable \u00e0 celles estim\u00e9es par Roques et al 2020 . On lisse la sortie en faisant une moyenne mobile sur 5 jours : IFRlisse <- rollmean(IFR, k=5) plot(t[1:length(IFRlisse)], IFRlisse, type =\"l\", xlab=\"Nombre de jours (du 1er janvier 2020 au 12 mars 2020)\", ylab=\"IFR\",ylim=c(0,0.01)) points(t, IFR) title(\"Evolution de l'IFR (ratio de letalite) lors de la premiere flambee\") Nous obtenons des valeurs d\u2019IFR du m\u00eame ordre de grandeur (0.8%) et de tendance comparable \u00e0 l'article de Roques et al 2020 .","title":"Estimation du taux de l\u00e9talit\u00e9"}]}